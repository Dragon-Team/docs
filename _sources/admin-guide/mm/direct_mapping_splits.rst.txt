.. SPDX-License-Identifier: GPL-2.0

=====================
Direct Mapping Splits
=====================

Kernel maps all of physical memory in linear/direct mapped pages with
translation of virtual kernel address to physical address is achieved
through a simple subtraction of offset. CPUs maintain a cache of these
translations on fast caches called TLBs. CPU architectures like x86 allow
direct mapping large portions of memory into hugepages (2M, 1G, etc) in
various page table levels.

Maintaining huge direct mapped pages greatly reduces TLB miss pressure.
The splintering of huge direct pages into smaller ones does result in
a measurable performance hit caused by frequent TLB miss and reloads.

One of the many lasting (as we don't coalesce back) sources for huge page
splits is tracing as the granular page attribute/permission changes would
force the kernel to split code segments mapped to hugepages to smaller
ones thus increasing the probability of TLB miss/reloads even after
tracing has been stopped.

On x86 systems, we can track the splitting of huge direct mapped pages
through lifetime event counters in ``/proc/vmstat``

	direct_map_level2_splits xxx
	direct_map_level3_splits yyy

where:

direct_map_level2_splits
	are 2M/4M hugepage split events
direct_map_level3_splits
	are 1G hugepage split events

The distribution of direct mapped system memory in various page sizes
post splits can be viewed through ``/proc/meminfo`` whose output
will include the following lines depending upon supporting CPU
architecture

	DirectMap4k:    xxxxx kB
	DirectMap2M:    yyyyy kB
	DirectMap1G:    zzzzz kB

where:

DirectMap4k
	is the total amount of direct mapped memory (in kB)
	accessed through 4k pages
DirectMap2M
	is the total amount of direct mapped memory (in kB)
	accessed through 2M pages
DirectMap1G
	is the total amount of direct mapped memory (in kB)
	accessed through 1G pages


-- Saravanan D, Jan 27, 2021
